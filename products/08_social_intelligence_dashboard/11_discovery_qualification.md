# Social Intelligence Dashboard • Discovery Qualification

Below is a practical, sales-ready discovery & qualification framework tuned to Brilliant Noise’s Social Intelligence Dashboard (SID). It combines BANT + MEDDIC thinking, explicit red‑flags, a numeric scoring model you can use in your CRM, and specific next steps mapped to score bands. Use this during discovery calls, qualification meetings, and internal deal reviews.

SECTION 1 — Quick orientation (how to use this)
- Aim: move from a cold lead to a funded pilot or disqualify quickly.
- Format: use the 10 discovery questions in first two meetings. Tag responses to BANT & MEDDIC fields in CRM. Score immediately after call.
- Prep to bring: one‑page SID value sheet (spot market shifts 6 months early), a one‑slide Weighted Resonance Index demo, a 2–3 market case study (auto / motorcycle), high‑level pricing tiers, pilot timelines, and security/compliance checklist.

SECTION 2 — 10 discovery questions (mapped to BANT + MEDDIC)  
For each question below: Purpose, “good” answer, follow‑ups and immediate red‑flag cues.

1) Budget (BANT) / Metrics (MEDDIC)
Question: “What budget have you allocated (or can be reallocated) for market intelligence / AI insight tools this year? How does this compare to other initiatives?”
- Purpose: confirm ability to pay at SID price bands.
- Good answer: explicit budget or willingness to repurpose £15k–£50k+; budget owner identified.
- Follow-ups: acceptable procurement model (pilot vs enterprise); ability to stretch for multi‑market.
- Red flags: “No budget” with no plan to create; only single‑line, low one‑off spend <£5k.

2) Authority (BANT) / Economic Buyer (MEDDIC)
Question: “Who signs off on investments in strategic intelligence and product tools — and who influences them day‑to‑day?”
- Purpose: identify economic buyer and influencers.
- Good answer: CMO, VP Product, Head of Strategy, or Innovation Director named with timeline.
- Follow-ups: ask to include buyer in next meeting.
- Red flags: no clear buyer, decisions dispersed across many small stakeholders.

3) Need / Pain (BANT & MEDDIC Identify Pain)
Question: “Tell me about the last time a product or market decision was wrong — what happened and what was the business impact?”
- Purpose: surface quantified pain and business case.
- Good answer: specific example, cited cost/impact (e.g., delayed launch, wasted features, £100k–£1M impact).
- Follow-ups: how often does this occur; who owns that risk?
- Red flags: no recollection of missteps or “we’re fine with current processes”.

4) Decision Criteria (MEDDIC)
Question: “What are the top criteria you’ll use to evaluate vendors (accuracy, multi‑market coverage, explainability, integration, vendor profile, price)?”
- Purpose: map product fit to their checklist.
- Good answer: importance placed on multi‑market coverage, validated sources, AI explainability, and integration.
- Follow-ups: weightings of each criterion.
- Red flags: evaluation solely on lowest price or “brand name” only.

5) Metrics / ROI (MEDDIC)
Question: “Which KPIs would define success for this initiative (e.g., reduce missteps, faster validation, improved forecast accuracy)? Any numeric targets?”
- Purpose: create measurable success criteria for pilot/ROI.
- Good answer: measurable targets (e.g., reduce product validation cycle by X weeks, avoid Y cost).
- Follow-ups: what timeframe for seeing impact?
- Red flags: no measurable KPIs / unwilling to commit to metrics.

6) Timing (BANT) / Decision Process (MEDDIC)
Question: “What is your timeline for resolving this need? Are there product launches, model cycles, or market entry dates driving it?”
- Purpose: align to “spot shifts 6 months early” value and determine urgency.
- Good answer: a concrete roadmap (e.g., upcoming model/program in 6–12 months).
- Follow-ups: procurement and pilot decision windows.
- Red flags: no timeline, or timeline >18 months (low urgency).

7) Champion (MEDDIC)
Question: “Who would be the day‑to‑day user and internal champion for this dashboard? Are they ready to push this internally?”
- Purpose: ensure internal advocacy for implementation.
- Good answer: named product/insights owner enthusiastic and empowered to coordinate pilots.
- Follow-ups: arrange an intro/demo with that champion.
- Red flags: no champion or champion lacks influence.

8) Technical / Data Governance (added critical dimension)
Question: “Do you have legal/privacy constraints or internal policies about using social data or third‑party AI tools? Any integration or SSO requirements?”
- Purpose: flag compliance or integration blockers early.
- Good answer: clear governance, willingness to sign DPA, can use third‑party AI outputs, SSO available.
- Follow-ups: get security/compliance contact; share SID compliance pack.
- Red flags: absolute ban on social listening data or external AI tools; impossible integration demands.

9) Geography / Market Scope (Need / Fit)
Question: “Which markets are a priority now, and how important is a multi‑market view to your strategy?”
- Purpose: confirm product fits (single market vs multi‑market).
- Good answer: 3+ markets or active expansion plans — aligns to multi‑market package.
- Follow-ups: which markets, data languages, critical competitive sets.
- Red flags: only one domestic market with no plans to expand.

10) Current Tools & Competitors (Need / Decision Criteria)
Question: “What tools or processes do you use for consumer insight today? What’s working / not working?”
- Purpose: position SID against existing stack and surface gaps.
- Good answer: existing tools give noise but lack validated predictive signals and multi‑market coverage.
- Follow-ups: integration points, which reports they use.
- Red flags: heavy investment in existing long‑term contracts that block replacement or pilots.

SECTION 3 — Red flag indicators for disqualification
If you see any of these, deprioritize or disqualify unless accompanied by mitigating evidence:

- Zero or immovable budget and no procurement path to create funding.
- No identified economic buyer or decision process >12 months with no urgency.
- No measurable pain or inability/unwillingness to define KPIs.
- Legal/regulatory ban on using social listening or third‑party AI outputs for insight.
- Only single market, small TAM, and no plans to expand (SID’s strength is multi‑market).
- Only price matters; vendor selection purely on lowest cost.
- No internal champion and low willingness from stakeholders to engage.
- Procurement insists on impossible enterprise governance terms before pilot (e.g., 12+ week security review without pilot).
- Company size below ICP (under €50M revenue) and product decisions are micro / ad hoc.
- Organization refuses to accept “predictive signals” as part of decision-making (cultural resistance to AI insights).

SECTION 4 — Ideal customer scoring (1–10 scale) — method and criteria
Scoring approach: rate six dimensions 1–10 immediately after discovery. Compute weighted average to produce an overall 1–10 score (round to nearest integer).

Dimensions & weights:
- Fit (industry + size + use‑case alignment) — weight 25%
  - 10 = Automotive/motorcycle OEM or tier‑1 with €50M+ revenue and multi‑market needs.
  - 1 = Outside target industry or micro business.
- Budget (available or likely) — weight 20%
  - 10 = Committed budget ≥£35k or clear path to fund a pilot ≥£15k.
- Authority / Decision Clarity — weight 15%
  - 10 = Economic buyer identified, engaged, timeline <3 months.
- Need / Urgency (product roadmap & pain) — weight 20%
  - 10 = Immediate pain tied to upcoming launches/market entry within 6–12 months.
- Technical & Legal Readiness — weight 10%
  - 10 = No blocking legal issues; integration and SSO are feasible.
- Champion Strength — weight 10%
  - 10 = Strong, senior internal champion ready to run pilot and rally stakeholders.

Example scoring formula:
Overall score = round( (Fit*0.25 + Budget*0.20 + Authority*0.15 + Urgency*0.20 + Tech*0.10 + Champion*0.10) )

Interpretation bands:
- 9–10 (Hot) — High priority, potential enterprise deal. Expect Pilot → Close in 4–12 weeks.
- 7–8 (Qualified) — Good fit; likely pilot. Nurture and accelerate decision-maker involvement.
- 5–6 (Warm) — Interesting; needs more work on budget/authority/metrics. Offer low friction PoV.
- 3–4 (Cold) — Low priority; nurture with content and re‑qualify in 3–6 months.
- 1–2 (Disqualify) — No immediate opportunity / mismatch. Record reason and archive.

SECTION 5 — Next steps & playbook by qualification score
Use these step templates and estimated timelines. Include recommended materials & stakeholders for each.

Score 9–10: “Close path — Immediate priority”
- Actions (days 0–14): Schedule executive briefing/demo with economic buyer + champion + Head of Product/CMO. Share tailored ROI case study and pilot SOW.
- Proposed offer: Multi‑market pilot (3 markets) or enterprise POC. Use price tier matching their budget (from £35k upward) + 8–12 week implementation.
- Deliverables: sample Weighted Resonance Index, back‑tested market signal example, integration plan, contract & security pack.
- Goal (30–90 days): Sign pilot → deliver PoV → expand to full implementation.
- Who to involve from Brilliant Noise: Engagement lead, data scientist, product strategist, security/compliance contact, executive sponsor (to align CMO).

Score 7–8: “Qualified — pilot likely”
- Actions (days 0–21): Run a focused discovery workshop (60–90 mins) with champion, product lead and insights team. Offer a single‑market PoV pilot (paid) — £15k – £25k, 6–8 weeks.
- Offer: Single‑market deep dive + dashboard access for a small user group, plus one strategic recommendations brief.
- Deliverables: 4–6 week early signals deliverable; clear KPI targets and success criteria for pilot.
- Follow-ups: schedule governance & procurement touchpoints; supply compliance pack.
- Goal (30–90 days): Secure pilot and show measurable outcomes that map to their KPIs.

Score 5–6: “Warm — needs further qualification”
- Actions (days 0–30): Ask for internal stakeholders meeting; offer a low‑friction diagnostic:
  - Option A: Paid micro-scan (1 market, ~£8–12k) — short deliverable with sample RRI scoring.
  - Option B: Free 2‑page market snapshot (limited scope) to prove insight quality.
- Deliverables: ROI micro-case, competitor signals snapshot, suggested roadmap for pilot.
- Follow-ups: nurture with targeted case studies, invite to industry webinar.
- Goal (60–180 days): Improve score to 7+ by securing budget/authority.

Score 3–4: “Cold — nurture”
- Actions: Send targeted content: case studies in automotive/motorcycle, short webinar invite on early signal detection, and an industry whitepaper. Ask for permission to recontact in 3–6 months.
- Deliverables: share product one-pager and a short exemplar of the Weighted Resonance Index.
- Goal: requalify when market entry or product cycle becomes active.

Score 1–2: “Disqualify / Archive”
- Actions: Log disqualification reason and next requalification trigger (e.g., “reach out if expanding to multiple markets”).
- Deliverables: none. Set CRM re‑engage reminder (6–12 months) only if a relevant trigger occurs.
- Goal: conserve resources.

SECTION 6 — Suggested objection responses & tactical tips
- “It’s too expensive” → Response: explain pilot options (single‑market at ~£15k) + ROI framing (help avoid typical £500k+ missteps). Offer phased scope.
- “We already have tools” → Response: demonstrate SID’s differentiator: weighted RRI across 20 attributes + 50+ validated sources and predictive lead time (~6 months). Offer a direct comparison trial against a current use-case.
- “Legal won’t allow social data” → Response: propose a privacy & data governance review; offer anonymised aggregated outputs, show SID’s compliance processes and DPA templates.
- “We need proof of ROI” → Response: propose a short paid PoV with defined KPIs and payback hypothesis; offer executive readout tying signals to forecast improvements.

SECTION 7 — CRM fields to capture after every discovery call
- ICP fit (Y/N, notes)
- Budget (amount, owner, committed?/available?)
- Economic buyer (name, role, contact)
- Decision timeline (target date)
- Top 3 decision criteria
- Named champion (name, role, influence level)
- Legal/compliance blockers (Y/N, details)
- Target markets list
- Current tools and key gaps
- Pain example (with estimated cost)
- Numeric score (1–10) and next recommended action (per section 5)

SECTION 8 — Hand-off checklist for pilot proposal
Before sending pilot proposal:
- Confirm economic buyer’s approval to pilot terms.
- Confirm champion will provide required access to stakeholders and internal data (if needed).
- Agree KPIs and success criteria in writing.
- Confirm legal/compliance signoff path and initial security questionnaire.
- Provide timeline & SOW with clear deliverables, costs, and expansion options.

FINAL NOTES — positioning reminders for reps
- Lead with outcomes: predictable product decisions, avoid £500K+ missteps, spot shifts ~6 months earlier.
- Emphasise Brilliant Noise strengths: AI + marketing transformation, Test‑Learn‑Lead™ approach, B‑Corp values (helps conversations with sustainability‑minded brands).
- Tailor examples to automotive/motorcycle product teams and multi‑market strategy leads.

If you want, I can:
- Convert the scoring rubric into a CRM-friendly field list or spreadsheet template.
- Draft an email template for each score band to request the next meeting or send a pilot proposal.

# AI Innovation Day • Discovery Qualification

Below is a practical, sales-ready discovery & qualification framework tailored to AI Innovation Day — built for Brilliant Noise’s target buyers (CMOs, CDOs, Innovation Directors, senior leaders at global brands). Use it in calls, qualification forms, or CRM fields. Each section gives actionable guidance you can deploy immediately.

1) DISCOVERY QUESTIONS (10) — organized to map both BANT and MEDDIC
For each question: short phrasing to ask, the intent (what you learn), which BANT + MEDDIC element it maps to, examples of an “ideal” answer, and “red‑flag” answers that suggest risk/disqualification.

1. “What specific business outcome would you want a working prototype to prove in one day?”  
   - Intent: Clarify need, success metric.  
   - BANT: Need / Timeline. MEDDIC: Metrics / Identify Pain.  
   - Ideal answer: “We need a prototype that demonstrates a 10% increase in conversion for product X, to secure a Q4 marketing budget.”  
   - Red flag: Vague desire for ‘innovation’ with no measurable outcome (“we want to ‘explore AI’”).

2. “Who will be the economic buyer and who needs to sign off for a ~£9k engagement?”  
   - Intent: Identify authority and purchasing route.  
   - BANT: Authority / Budget. MEDDIC: Economic Buyer / Decision Process.  
   - Ideal: “The Head of Innovation + VP Marketing approve up to £25k; procurement approves T&Cs within 2 weeks.”  
   - Red flag: “We don’t know who signs off” or procurement requires multi-month vendor onboarding.

3. “Do you have budget confirmed for a rapid prototype engagement (approx. £8.8k) or will funding need to be reallocated?”  
   - Intent: Budget availability & speed to buy.  
   - BANT: Budget. MEDDIC: Economic Buyer.  
   - Ideal: “Yes — line item for innovation testing exists and can be approved this month.”  
   - Red flag: “No budget; need to apply for funding and wait several months.”

4. “How quickly do you need results? Is there a board date or campaign deadline we need to target?”  
   - Intent: Timeline urgency and decision window.  
   - BANT: Timeline. MEDDIC: Decision Process.  
   - Ideal: “We need a demo by mid‑next month for the executive board.”  
   - Red flag: “No fixed timeline or timeline >3 months (low urgency).”

5. “What internal stakeholders (data, product, marketing, legal) can attend and give access during the day?”  
   - Intent: Validate team availability & permissions needed for a live prototype.  
   - BANT: Need/Authority. MEDDIC: Decision Process / Champion.  
   - Ideal: “Product lead, 2 marketers, and an engineer can attend and provide datasets/APIs.”  
   - Red flag: “Only junior staff available; no data access or engineering time.”

6. “Tell me about the data, content or systems we’d need to prototype — is this accessible and ready for a short test?”  
   - Intent: Technical feasibility & data readiness.  
   - BANT: Need. MEDDIC: Identify Pain / Decision Criteria.  
   - Ideal: “We have anonymised sample data and a content API we can open for a day.”  
   - Red flag: “All data is locked away; legal refuses to share anything even for a demo.”

7. “What would make leadership say ‘yes’ after seeing a live prototype?”  
   - Intent: Understand decision criteria and acceptance threshold.  
   - BANT: Need / Authority. MEDDIC: Decision Criteria / Metrics.  
   - Ideal: “They need to see measurable uplift, a clear go‑to‑market plan, and low technical risk.”  
   - Red flag: “Leadership wants a full production-ready solution immediately.”

8. “Have you run any prior pilots or worked with consultancies on AI/product experiments? What worked and didn’t?”  
   - Intent: Assess past experience, risk tolerance, and vendor expectations.  
   - BANT: Need / Authority. MEDDIC: Champion / Identify Pain.  
   - Ideal: “We ran two short pilots — one reached board buy-in, one stalled due to scope creep; we want tighter scope.”  
   - Red flag: “Previous vendors overpromised and underdelivered and procurement bans external pilots.”

9. “If we delivered a working prototype and blueprint in one day, what are the next steps you’d expect to take?”  
   - Intent: Gauge post‑workshop appetite to scale and budget for follow‑on work.  
   - BANT: Budget / Timeline. MEDDIC: Metrics / Decision Process.  
   - Ideal: “We’d brief engineering for a 3‑month build and assign a budget holder immediately.”  
   - Red flag: “No plan or appetite to progress beyond a demo.”

10. “On a scale of 1–10, how important is speed of validation vs. perfection for this initiative?”  
   - Intent: Assess cultural fit for a ‘prototype-in-a-day’ approach.  
   - BANT: Need / Timeline. MEDDIC: Identify Pain / Champion.  
   - Ideal: “9 or 10 — we prioritise speed and proof-of-value.”  
   - Red flag: “1–3 — we only accept production-ready, near-perfect outputs.”

2) RED FLAGS — immediate indicators for disqualification or heavy caution
If any of these are true, pause standard close-play and either disqualify or move to long-term nurturing with clear expectations.

- No executive sponsor/economic buyer identified or engagement is purely with junior staff. (Decision bottleneck)
- No budget or no realistic path to secure ~£8.8k within the quarter. (Budget risk)
- Procurement or legal requires lengthy enterprise onboarding before delivery (>6 weeks). (Timeline risk)
- Stakeholders cannot commit people for the full day or cannot provide minimal data/access for prototyping. (Delivery infeasible)
- Client expects a fully productionised, enterprise‑grade solution out of the day (misaligned expectations). (Scope mismatch)
- Organization has zero prior appetite for rapid experimentation or has killed prior pilots at exec stage. (Cultural misfit)
- Mandatory vendor exclusivity or policies blocking the use of third‑party AI tools used in prototyping. (Tech/legal blocker)
- Use-case too broad or cross‑enterprise without a bounded MVP scope (e.g., “AI for customer experience across all markets” with no focus). (Unscoped)
- Target metrics are irrelevant for a one‑day prototype (asks for long-term brand lift proofs only). (Unmeasurable)
- Competitive preference for large consultancies or existing long-term vendor relationship that won’t allow a boutique to run the day. (Procurement preference)

3) IDEAL CUSTOMER SCORING CRITERIA — 10-point scale, 10 criteria, total score out of 100
Score each criterion 1 (poor fit) to 10 (perfect fit). Use the descriptions to score quickly in calls. High scores indicate immediate qualification.

Scoring guidance (what 10 vs 1 looks like) included for each:

1. Strategic fit / Use-case suitability (1–10)  
   - 10: Narrow, well-defined use case that can be prototyped in a day (e.g., campaign creative automation, product recommendation flow).  
   - 1: Vague, enterprise-wide transformation with no MVP scope.

2. Business outcome clarity & metrics (1–10)  
   - 10: Clear KPI (conversion rate, campaign response, time saved) tied to decision.  
   - 1: No measurable outcome.

3. Executive sponsor / economic buyer clarity (1–10)  
   - 10: Named sponsor with approval authority visible and engaged.  
   - 1: No sponsor, only junior contacts.

4. Budget availability & approval path (1–10)  
   - 10: Budget exists and can be approved within current quarter (~£8.8k available).  
   - 1: No budget and long approval process.

5. Timeline urgency (1–10)  
   - 10: Tight deadline or board date within 1–6 weeks requiring fast validation.  
   - 1: No urgency (6+ months).

6. Cross‑functional availability (1–10)  
   - 10: Product, marketing, data, and engineering stakeholders can commit to the day.  
   - 1: Only peripheral staff available.

7. Data / tech readiness (1–10)  
   - 10: Sample data/APIs accessible for demo; no legal block for demo use.  
   - 1: No access, strict legal constraints.

8. Decision process speed & clarity (1–10)  
   - 10: Fast, clear process: decision within 2–4 weeks post-demo.  
   - 1: Decision process unknown/opaque & multi-month.

9. Cultural fit / appetite for rapid experimentation (1–10)  
   - 10: Leadership prioritises speed/proof over perfection and has a history of rapid pilots.  
   - 1: Risk-averse, prefers full specs and long development cycles.

10. Potential to scale / follow-on value (1–10)  
   - 10: Clear path to a multi‑month build or enterprise rollout if prototype succeeds.  
   - 1: No appetite to progress beyond a demo.

Scoring example:
- Tally points for each criterion to get a score out of 100.
- Optional: Weight certain criteria higher (e.g., Budget, Sponsor, Use‑case) — if you want this, multiply those by 1.5 before summing.

Interpretation bands (recommended):
- 85–100 (Excellent fit): Green — immediate pursue and close.  
- 65–84 (Good fit): Yellow — pursue after clearing 1–2 risks.  
- 45–64 (Marginal): Orange — nurture and deal with blockers; consider smaller engagement or pre-work.  
- 0–44 (Poor fit): Red — disqualify or nurture long-term.

4) NEXT STEPS — actions mapped to qualification bands (detailed, actionable)

If score 85–100 (Excellent fit) — Close & Execute
- Action steps (0–7 days):  
  - Send tailored one‑page proposal + SOW for AI Innovation Day (includes deliverables, participant list, prep requirements).  
  - Propose 2 available workshop dates within 2–4 weeks.  
  - Request sign-off from economic buyer and circulate simple T&Cs + invoice schedule (50% deposit or full via PO).  
  - Share pre-work checklist: defined use case, stakeholder list, sample data, access requirements, NDAs if needed.  
  - Pre-work call (30 mins) to lock scope and success metrics.  
- Sales assets: short case study (adidas/Nestlé) showing day -> board buy-in, sample agenda, logistics checklist.  
- Messaging: emphasise speed, low cost vs months of internal development, leadership buy-in, Test‑Learn‑Lead™.

If score 65–84 (Good fit) — Confirm & Mitigate Risks
- Action steps (within 1–3 weeks):  
  - Book discovery workshop (30–60 mins) with sponsor + procurement + technical owner to close outstanding risk (budget approvals, legal).  
  - Provide a “risk checklist” highlighting the red flags identified and proposed mitigations (e.g., limited data = synthetic/sampled data option).  
  - Offer a slightly amended scope (e.g., focused sub-use-case) to guarantee deliverable in a day.  
  - Offer flexible payment or pilot agreement if procurement is hesitant.  
- Sales assets: ROI estimate template, risk mitigation options, introduction to technical lead who will run the day.

If score 45–64 (Marginal) — Nurture or Alternative Offer
- Action steps:  
  - Recommend a lighter, lower-friction activity first (e.g., a 2-hour scoping session or ‘use-case sprint’ at lower cost) to build trust.  
  - Provide a case study emphasizing how a tightly scoped day avoids scope creep.  
  - Schedule a 4–6 week follow-up to reassess budget/ timeline.  
  - If the main blocker is procurement/globals, offer to run a pilot with a local country team or test case.  
- Sales assets: low-cost scoping offer, boilerplate contract language for procurement, short proof-of-value decks.

If score <45 (Poor fit) — Disqualify or Long-term Nurture
- Action steps:  
  - Politely disqualify in CRM with reason codes (no budget, no sponsor, legal block, wrong expectation).  
  - Leave a nurture plan: send quarterly insights, relevant case studies, and invitations to webinars or an annual industry AI briefing.  
  - If misaligned on scope (want production solution), offer an introduction to scaled implementation partners once they’re ready.  
- Messaging: keep relationship warm and positioned as the rapid validation partner when they’re ready.

5) SELLER PLAYBOOK — practical steps & templates to operationalise qualification
- Call agenda (30 mins): 1) Quick intro & credibility (2m), 2) Use-case & KPIs (8m), 3) Stakeholders & budget/timeline (8m), 4) Tech/data & legal (6m), 5) Next steps & close (6m).  
- Pre-work checklist to send after qualification call: participant names, success metric, sample data (or explanation if not possible), 1‑page use case statement, PO/finance contact.  
- Contract & pricing guidance: standard SOW for £8,800; request PO or 50% deposit on booking; offer fast-track invoice process for known global brands.  
- Logistics & delivery prerequisites (must-haves before delivering the day): executive sponsor committed, 4–6 cross‑functional participants reserved for the day, minimal data or content access, agreed success metric.  
- Follow-on offering: 4‑8 week rapid build-retainer or scaled programme (Test-Learn-Lead™ roadmap) — include approximate costs and typical timeline to avoid “we expect production” confusion.

6) EXAMPLES — quick templates you can paste into CRM notes
- Qualification summary line (one-sentence): “Targeting conversion uplift for product X; sponsor (Head of Innovation) confirmed; budget allocated; data/API available; board demo required in 3 weeks — Score 88/100 (book AI Innovation Day).”  
- Disqualification note template: “Disqualified — no budget & no sponsor. Nurture quarterly. (Red-flag: procurement blocks third-party AI use).”

Final notes — practical reminders
- The product’s core promise is speed + tangible demo. Always align discovery to prove that the use case is narrow, measurable, and has an executive use for the demo.  
- Bridging procurement/legal friction is often the biggest risk — build standardized T&Cs, a simplified SOW, and an NDA template to accelerate approval.  
- Use the “red flags” as explicit CRM fields so reps routinely capture them and escalate to pre-sales when needed.  
- Train AEs on short-case studies and one-liners demonstrating commercial outcomes (e.g., “Saved 3–6 months of dev time, used to secure multi‑mth budgets”) — these sell the day better than technical specs.

If you’d like, I can:
- Convert the 10 discovery questions into a one-page qualification checklist for reps/CRM.
- Provide sample email templates (proposal, pre-work checklist, disqualify message).
- Create a weighted scoring sheet if you want certain criteria to count more.
